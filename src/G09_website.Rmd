---
author: "B08608054 陳品睿 B08b02061 陳亦萲 B09303105 許庭瑜 B09303065 賴迎曦"
title: "台大學生都在在想什麼？— 試析台大學生共識議題之轉變"
output: 
  html_document:
    number_sections: yes
    highlight: tango
    toc: yes
    toc_float:
      collapsed: no
    css: style.css
runtime: shiny
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,comment = '#>',error=TRUE, results = 'hold', out.width='70%', fig.align = 'center', message = FALSE)
```

研究動機
==================

上個月，臉書的臺大交流版充斥著對於一年一度學生會會長的討論，從宿舍、社團、到各種學生權益的爭取，候選人無不絞盡腦汁想出最能博得大家喜愛的政見。這樣的學生會長選舉已經行之有年，面對每學年度都會大量出現的政見，我們想藉此了解近十年來學生們的想法：
1.  臺大學生在意的議題有哪些？
2.  是否一直存在著還沒有被解決的難題？這些難題經過了長時間的討論後，大家關注的面向有沒有改變？ 

資料來源
==================

我們與臺大學生會選委會聯繫過後，對方表示未曾有人整理歷年來之選舉政見，因此我們的資料出自二處：

1. **粉專爬文**(104~109學年度): 自臺大學生會選委會的[粉專](https://www.facebook.com/NTUVote)，找出每年度「選舉公報」中之學生會會長候選人的政見，將其儲存成txt文字檔。

2. **查找PTT**(97~103學年度): 這七年的政見皆有人整理放在[PTT](https://term.ptt.cc/)網站中，同樣儲存成txt文字檔。

我們將蒐集的資料共同儲存在「science_data」資料夾中，以便分析。

由於96學年度以前的學生會會長候選人政見不曾有人整理，因此我們只蒐集`97至109學年度`共13年、`33`筆資料，總字數為`67827`字。

分析方法
==================

起初，我們使用了課堂上學到的斷詞、製作詞頻表的技巧來分析這些政見，；然而，停用詞典的效果比我們預期的低許多、英文政見影響了結果、各種「的、與、和」等介系詞和連接詞也干擾了分析，因此決定使用CKIPtagger將政見標註詞性，以及加入了Textrank透過關鍵句來展示結果，儘管上面的問題有獲得解決，但是每個方法都各有利弊。下方將詳細說明我們的程式碼，並比較每個年度用各種分析方法的結果：

## 環境安裝

```{r}
library(shiny)
library(pacman) 
p_load(tidyverse,tidytext,textrank,rio,jiebaR)
library(quanteda)
library(readr)
library(stringr)
library(dplyr)
library(tidytext)
library(jiebaR)
library(httr)
library(magrittr)
library(rvest)
library(highcharter)
```

## 讀取多個檔案
* fps: 列出全部的檔名
* title: 全部的文章
* 說明：透過title[輸入數字]，可讀取某一年所有政見文章
    
```{r}
fps <- list.files("./Politics_txt_by_years", full.names = T)

title <- vector()
for (i in seq_along(fps)) {
    title[i] = read_file(fps[i])
}
```

## 斷詞、建立詞頻表
* candidate函數
* 說明：candidate(title[輸入數字])，可以得到前三個頻率最高的詞
    
```{r}
#在外部構造一個jieba分詞器 
seg <- worker(user = "./user_dict.txt", stop_word = "./stop_word.txt")

#candidate函數
candidate <- function(x) {
    #斷詞
    docs_segged <- vector("character", length = length(x))
    segged <- paste0(segment(x, seg), collapse = "\u3000")
    docs_df <- tibble::tibble(
        doc_id = seq_along(docs_segged),
        content = segged
    )
    knitr::kable(docs_df, align = "c")
    #詞頻表
    frequency_df <- docs_df %>%
        unnest_tokens(output = "word", input = "content")%>%
        group_by(word) %>%
        summarise(n = n()) %>%
        top_n(3,n) %>%   #更改數字n，前n名出現最高的詞
        arrange(desc(n))
    frequency_df
}
```

## 長條圖
* chart函數

```{r}
year <- function(x){
    for(i in length(x)){
        segged <- segment(x[i], seg)
        x[i] <- paste0(segged, collapse = "\u3000")
    }
    df1 <- tibble::tibble(
        id = seq_along(x),
        content = x
    )
    knitr::kable(df1, align = "c")
    df2 <- df1 %>%
        unnest_tokens(output = "word", input = "content")
    df3 <- df2 %>%
        group_by(word) %>%
        summarise(n=n()) %>%
        arrange(desc(n))
    return(df3)
}
chart <- function(x){
    highchart() %>%
        hc_chart(type = "bar") %>%
        hc_xAxis(categories = x$word) %>%
        hc_add_series(name = "Frequency", data = x$n) %>%
        hc_title(text = "詞彙分布圖")
}
```

## tf-idf
```{r}
tf_idf <- function(x){
    key = worker("keywords", topn = 20)
    vector_keywords(seg[x], key)
}
```

## Textrank
透過Textrank找出每份政見中和每一句話相關性最強的句子，視為關鍵句(文章摘要)
* sentences函數
* 說明：sentences(輸入數字)，可以得到前n個關鍵句(相關性由高到低排列)
  
```{r}
sentences=function(x){
get_sentence_table = function(string){ 
    string %>% 
        str_split(pattern = "[:space:]+") %>% 
        unlist %>% 
        as_tibble() %>% 
        transmute(sentence_id = 1:n(),sentence = value) 
}

get_word_table = function(string){ 
    string %>% 
        str_split(pattern = "[:space:]+") %>% 
        unlist %>% 
        as_tibble() %>% 
        transmute(sentence_id = 1:n(),sentence = value) %>% 
        mutate(words = map(sentence,segment,jieba = seg)) %>% 
        select(-sentence) %>% 
        unnest(cols = c(words)) 
}
test_text = title[x]
st = test_text %>% get_sentence_table 
wt = st%>% get_word_table  

textrank_sentences(data = st,terminology = wt) %>% 
    summary(n = 3)  #n代表要top多少的關鍵句子
}
```
## CKIPtagger
除了jiebaR，我們還利用了中研院開發的斷詞系統進行斷詞以及繪製詞頻表，然而CKIPtagger是python的模組，因此我們須將python移植到R，並且還需載入大量的模型檔，因此我們將結果製作成另一個[html檔](https://drive.google.com/file/d/1SAQQQxP5dU8Ur16PgsqqFbLr51ukvcW7/view?usp=sharing)，[或點這裡](./CKIPtagger/finalproject_ckiptagger.html)。

 讀檔與結果
==================

## 109年
```{r}
#詞頻表
candidate(title[11])
chart(year(title[11]))
```
```{r}
#tf_idf
tf_idf(title[11])
```
```{r}
#Textrank
sentences(11)
```
## 108年
```{r}
#詞頻表
candidate(title[10])
chart(year(title[10]))
```
```{r}
#tf_idf
tf_idf(title[10])
```
```{r}
#Textrank
sentences(10)
```
## 107年
```{r}
#詞頻表
candidate(title[9])
chart(year(title[9]))
```
```{r}
#tf_idf
tf_idf(title[9])
```
```{r}
#Textrank
sentences(9)
```
## 106年
```{r}
#詞頻表
candidate(title[8])
chart(year(title[8]))
```
```{r}
#tf_idf
tf_idf(title[8])
```
```{r}
#Textrank
sentences(8)
```
## 105年
```{r}
#詞頻表
candidate(title[7])
chart(year(title[7]))
```
```{r}
#tf_idf
tf_idf(title[7])
```
```{r}
#Textrank
sentences(7)
```
## 104年
```{r}
#詞頻表
candidate(title[5])
chart(year(title[5]))
```
```{r}
#tf_idf
tf_idf(title[5])
```
```{r}
#Textrank
sentences(5)
```
## 103年
```{r}
#詞頻表
candidate(title[4])
chart(year(title[4]))
```
```{r}
#tf_idf
tf_idf(title[4])
```
```{r}
#Textrank
sentences(4)
```
## 102年
```{r}
#詞頻表
candidate(title[3])
chart(year(title[3]))
```
```{r}
#tf_idf
tf_idf(title[3])
```
```{r}
#Textrank
sentences(3)
```
## 101年
```{r}
#詞頻表
candidate(title[2])
chart(year(title[2]))
```
```{r}
#tf_idf
tf_idf(title[2])
```
```{r}
#Textrank
sentences(2)
```
## 100年
```{r}
#詞頻表
candidate(title[1])
chart(year(title[1]))
```
```{r}
#tf_idf
tf_idf(title[1])
```
```{r}
#Textrank
sentences(1)
```
## 99年
```{r}
#詞頻表
candidate(title[14])
chart(year(title[14]))
```
```{r}
#tf_idf
tf_idf(title[14])
```
```{r}
#Textrank
sentences(14)
```
## 98年
```{r}
#詞頻表
candidate(title[13])
chart(year(title[13]))
```
```{r}
#tf_idf
tf_idf(title[13])
```
```{r}
#Textrank
sentences(13)
```
## 97年
```{r}
#詞頻表
candidate(title[12])
chart(year(title[12]))
```
```{r}
#tf_idf
tf_idf(title[12])
```
```{r}
#Textrank
sentences(12)
```

 結論與分析
==================

(放excel的圖)

## 臺大學生在意的議題有哪些？
* 我們根據Textrank的關鍵句，從每年政見中找出被大家關注的三個議題，再將這些議題分類歸納。進而發現，以下是十年中有被重複提過的議題，而我們認為這些最可能是台大學生在意的議題。

參選預算、文化與藝術、性別友善、社會回饋、選舉制度改善、技術交流(跨領域、跨國際)、空間分配、學生自治

## 是否一直存在著還沒有被解決的難題？
* 我們根據以上議題，我們在將他們的年份列出，發現其中**文化與藝術**、**選舉制度改善**、**空間分配**，相隔五年以上又被提出。由於我們這次所研究的資料為97~109年(約有13年)，因此五年將近一半，而認為這些可能是沒有被解決的難題。然而，不排除此議題本身並非一個需被解決的難題(如:文化與藝術)，而是每個年度大家都會關注的議題，所以一再被提出。

參選預算(109,106)
文化與藝術(109,100,98,97)
性別友善(108,104,103)
社會回饋(100,99)
選舉制度改善(105,97)
技術交流(跨領域、跨國際)(102)
空間分配(107,103,99)
學生自治(101,98,97)

## 這些難題經過了長時間的討論後，大家關注的面向有沒有改變？
* 我們再將上面的議題，重新按時間順序排列後，會發現從學生會長提出的政見中，議題有這樣的演變關係。值得關注的是，在104年時，其實學生會長有進行補選，而105年中**選舉制度改善**為分析該年的重點議題，可以預測此方法，應該還是有一些可信性。


近期：參選預算(109,106)
   性別友善(108,104,103)
   技術交流(跨領域、跨國際)(102) 兩個議題
早期：學生自治(101,98,97)
         社會回饋(100,99)
